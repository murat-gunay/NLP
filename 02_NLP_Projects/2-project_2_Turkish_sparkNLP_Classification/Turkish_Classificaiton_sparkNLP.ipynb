{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turkish_Classificaiton_sparkNLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMBCPx/rbMc8IK9XleafDvS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/murat-gunay/NLP/blob/master/02_NLP_Projects/2-project_2_Turkish_sparkNLP_Classification/Turkish_Classificaiton_sparkNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4_9JboFuRqY"
      },
      "source": [
        "# Classification of the Text in Turkish using Spark NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WXrXp2tufyP"
      },
      "source": [
        "## Initializing of PySpark & Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkG0L-e6_Nk8",
        "outputId": "13f788b4-306e-43d7-c42e-2f29d38e5eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.6.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 67kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 34.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130389 sha256=9b7c02bb713c48522fe428b99bfa20dc28fe7739af4a745834e48b4af40175e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/de/6db7be666e7c8b70d39bcb0d956d3d983bcb06ea3895308c84d7a131dfb1/spark_nlp-2.6.2-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBwi1G5Quus4"
      },
      "source": [
        "## Starting of Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk90GIqb_ot_",
        "outputId": "4459608e-5e4d-412c-826b-d3dfb5009f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "print(\"Version of SparkNLP:\", sparknlp.version())\n",
        "print(\"Version of Spark :\", spark.version)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0uNJ_S5_6uI"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1dlMl4ZuJmA"
      },
      "source": [
        "## Loading and Reading the DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esO7pi3ei_zV",
        "outputId": "14053dc0-df37-441c-a14d-09a44cf1034d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/murat-gunay/NLP/master/02_NLP_Projects/2-project_2_Turkish_sparkNLP_Classification/turkish_categorical_corpus.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-06 07:20:07--  https://raw.githubusercontent.com/murat-gunay/NLP/master/02_NLP_Projects/2-project_2_Turkish_sparkNLP_Classification/turkish_categorical_corpus.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10627541 (10M) [text/plain]\n",
            "Saving to: ‘turkish_categorical_corpus.csv’\n",
            "\n",
            "turkish_categorical 100%[===================>]  10.13M  54.5MB/s    in 0.2s    \n",
            "\n",
            "2020-10-06 07:20:08 (54.5 MB/s) - ‘turkish_categorical_corpus.csv’ saved [10627541/10627541]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wplqo9HOjL_F"
      },
      "source": [
        "df_Spark = spark.read \\\n",
        "           .option(\"header\", True) \\\n",
        "           .csv(\"turkish_categorical_corpus.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcVJYMVpjUit",
        "outputId": "17baebc9-90fa-47da-8a2b-090e30495262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "df_Spark.show(5, truncate=55)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------------------------------------------------------+\n",
            "|category|                                                   text|\n",
            "+--------+-------------------------------------------------------+\n",
            "|siyaset | 3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük...|\n",
            "|siyaset | mesut_yılmaz yüce_divan da ceza alabilirdi prof dr ...|\n",
            "|siyaset | disko lar kaldırılıyor başbakan_yardımcısı arınç di...|\n",
            "|siyaset | sarıgül anayasa_mahkemesi ne gidiyor mustafa_sarıgü...|\n",
            "|siyaset | erdoğan idamın bir haklılık sebebi var demek ki yer...|\n",
            "+--------+-------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgtzZiC1j3Ni",
        "outputId": "c4482df7-892d-4ad4-f089-950af8d11358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df_Spark.groupBy(\"category\").count().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|  category|count|\n",
            "+----------+-----+\n",
            "|   kultur |  700|\n",
            "|  siyaset |  700|\n",
            "|teknoloji |  700|\n",
            "|   saglik |  700|\n",
            "|  ekonomi |  700|\n",
            "|     spor |  700|\n",
            "|    dunya |  700|\n",
            "+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcHisAO6o_X8"
      },
      "source": [
        "## Removing extraneus underscores from the documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdN_cHDEmRwL",
        "outputId": "39ed9657-2f59-46ce-89f4-c7c99b66cad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "df_Spark.take(2)\n",
        "\n",
        "# We should remove the \"_\" (underscores) between nouns. e.g.: \"mesut_yılmaz\", \"koray_aydın\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(category='siyaset ', text=' 3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı koray_aydın seçimlerden önce partinin üye sayısının 3 milyona ulaştırılması hedefini koyarak ön seçim uygulaması vaadinde bulundu genel_başkan adayı koray_aydın kürsüye beklenirken yapılan tezahüratlar ve ıslıklamalar üzerine divan başkanı tuğrul_türkeş mhp nin genel başkanlığı da genel başkan adaylığı da saygıdeğer işlerdir bu salondaki herkes ciddiye almak zorundadır dedi ve taşkınlıklara izin verilmeyeceğini salonda sükunet sağlanmadan konuşmaların başlamayacağını vurguladı türkeş devlet_bahçeli nin kurultay açılışında konuştuğu için adaylık nedeniyle ikinci bir konuşma yapmayacağını açıkladı konuşmasında kurultayın mhp nin tek başına iktidarına vesile olmasını dileyen aydın ak_parti nin mhp yi eleştirirken kaleleri bir bir fethederek yollarına devam ettiklerini söylediğini hatırlatarak iktidarın basın ve sivil toplumu susturduğunu ifade etti ak_parti nin bürokraside taş üstüne taş bırakmadığını ileri süren aydın ülkücüleri düşman kabule ederek onları kıyma makinelerinden geçirecek bir zihniyetle sürgün ederek oraya buraya saldırarak bürokrasideki ülkücü kadrolara savaş açtılar dedi yaşanan bütün skandalların ardından devleti çete mantığıyla yöneten siyasi iktidarın olduğunu savunan aydın iktidarın belediyelere sahte raporlarla ve dinlemelerle saldırdığını savunan aydın arkasından habur dan içeri soktukları vatan hainlerine karşılama törenleri yetmez gibi oslo da teröristlerle kurdukları pazarlık masalarında suçüstü yakalanınca da ben görmedim diyerek bunu ispat edecek biri varsa şerefle ispat etsin diyerek ses kayıtları çıkınca da kıvırarak sahiplenemeyerek yaptığı işin üzerine şal örtmeye çalışarak siyasi riyakarlıkta sınır tanımayan siyasi iktidarla karşı karşıyayız diye konuştu mintika temizliği yapiyorlar ak_parti nin ne yaptığını iyi bildiğini türkiye de ihtilal teşebbüsü var diyerek ordunun subaylarını yargılama adı altında cezaevine koyduğunu savunan aydın önce milletin bu darbeciler ortadan kalksın diyerek desteklediği sonra plan gereği sürek avına çevirerek türk ordusunun neredeyse yarısını içeri atan bu zihniyet mıntıka temizliği yapıyor kuracakları yeni türkiye modeline engel olmasın diye bunları kaldırıyorlar bu işi haince yapanlar ne zaman ki şehit cenazeleri türkiye yi ağlatmaya başlarken acılarımızla yaşarken türkiye nin başbakanı gerekirse öcalan la yeniden görüşebilirim diyor sayın_başbakan ne görüşeceksin öcalan la ne söyleyeceksin oraya bir masa koymuşsun masanın üstünde türkiye karşında öcalan ne kadar istiyorsun şu kadar versem yeter mi diyeceksin öcalan yüzsüzlük eder de türkiye nin tamamını isterse ne yapacaksın diye konuştu o zaman ne yapacağiz yeni anayasa kapsamında türk milletinin adının anayasadan çıkarılarak bir alt kimlik haline getirileceğini türk milletine etnisite temelli yaklaşılacağını savunan aydın bu_türk milletinin varlığını ötüken de söğüt te türk olan türk milletinin varlığını ortadan kaldırma çabasıdır bu işin sonudur çünkü şu anda kendisiyle benzeşen anamuhalefetle anlaşıp anayasadan türk milletinin adını çıkarırlarsa yapılacak bir şey kalmaz meclis sayısal çoğunlukla yönetiliyor bunlar sinsi her işi alttan alttan götürüyorlar böyle bir adım atar bu büyük milletin adını çıkararak türk milletini bir alt kimlik haline dönüştürürlerse ne yapacağız bunu yaparlarsa 5 yıl 10 yıl sonra bu ülkenin adının türkiye olmasına gerek yoktur derlerse ne yapacağız bu sinsi planı iyi görelim bunu için bir şeyler yapmamız harekete geçmemiz lazım dedi şubat ta 1 milyon olarak toplanirsak … kimsenin türkiye de olanlara arkasını dönemeyeceğini ifade eden aydın özetle şunları söyledi meydanlara ineceğiz türk milletine gideceğiz milletle bütünleşeceğiz onu bekleyen bu tehlikeler hakkında uyaracağız anlatacağız onu yanımıza almaya çalışacağız o büyük gücü harekete geçirir meydanlara iner onların dikkatini çekip yanımıza alırsak şubat ayında 1 milyon olarak toplanırsak hangi vatan hainleri bunu yapmaya cesaret edebilir türk milletinin bunu anlamasını sağlamamız lazım bunun için güçlü bir mhp ye ihtiyaç var 43 yıllık fikri birikimi üzerinden türk milletini bütün problemlerine getireceği çözüm önerilerini bir iktidar projesine dönüştürerek türk milletini karşısına çıkıp iktidar istersek bu coşku ve heyecanı ona aksettirirsek bu millet bu şaşkınlıkla etrafına bakınırken ben nereye bakacağım sorusunu sorarken bu millet elimizi tutacak ve mhp ile yeniden ayağa kalkacaktır hedef 3 milyon üye bu mücadelede ilk doğru adımın ülkücü hareketin birliğini ve dirliğini sağlamak olduğunu kaydeden aydın harekete bir gün bile hizmet etmiş her ülküdaşlarıyla kucaklaşmak ve bir araya gelmek mecburiyetinde olduklarını ifade etti ülkücüleri ülküdaşlık hukuku temelinde kaynaştırmadan büyük hedeflere yürüyemeyeceklerini anlatan aydın bunu temel hareket noktası kabul ediyoruz birey temelli bir hareketin başlaması için önce partide üyelik sistemini bir kampanyaya çevireceğiz seçime kadar 3 milyon üye yaparak ailelerimizin fertlerini genişleteceğiz bunu iller arası yarışa çevireceğiz mhp nin 3 milyon üyeli geniş aile haline gelmesini sağlayacağız dedi önseçim vaadi genel_başkan seçilmesi halinde mhp ailesini genişleteceğini kaydeden aydın bunu yapınca bu 3 milyon kişi kurulan sandıklarla yapacağı bir ön seçimi size vaat ediyorum bunu taban güvenmek demektir böyle bir ön seçim yapıldı mı ankara da kimse genel merkez katlarında dolaşmayacak tabana size gidecek hasta olanın düğünü olanın yanında olacak yere düşeni ayağa kaldıracak böylece bu büyük aile fertleri bir birini anlayacak bu güzel sözün olduğu ortamın inşası demektir bu kötü söz olanın tasfiye edileceği liyakatın esas alınacağı yeni bir sistemin gelmesin demektir bu adımı atar aile fertleri arasında huzuru sağlarsak örgütlenme modelini buna paralel değiştirirsek mhp nin içinde huzur sağlanır diye konuştu bu bir kişiyi korumak için kelle avcısı rolü üstlenip ülküdaşlarını yok farz ederek küskünler ordusu yarattığın bir sitemin anlaşılması demektir diyen aydın mhp her yerde sloganıyla parti içinde hareketlilik sağlayacaklarını halka dokunacaklarını ifade etti ve tabanla bütünleşmiş mhp ye ihtiyaç var bunun içi bir iktidar projesi koyarak aday olduk biz iktidar olmak istiyoruz dedi aydın türk milletinin yalnızlığı yaşadığı bir durumda etrafına bakındığı kendini kaldıracak birini bekleyen türkiye nin mhp nin kendisine ulaşmasıyla yarın elbet bizimdir diye haykıracağını ifade etti haber anka foto emre senoglu murat oztek'),\n",
              " Row(category='siyaset ', text=' mesut_yılmaz yüce_divan da ceza alabilirdi prof dr sacit adalı isviçre deki banka eski başbakan mesut_yılmaz ın bankada 14 milyon doları var iddiasına cevap verseydi yüce_divan da hakkında verilen karar daha farklı olabilirdi dedi anayasa_mahkemesi eski üyesi turgut_özal üniversitesi hukuk_fakültesi dekanı prof dr sacit adalı isviçre deki banka eski başbakan mesut_yılmaz ın bankada 14 milyon doları var iddiasına cevap verseydi yüce_divan da hakkında verilen karar daha farklı olabilirdi dedi adalı yüce_divan ın rüşvet aldığı iddia edilen eski yargıtay 6 hukuk_dairesi başkanı hasan erdoğan ile rüşvet vermekle suçlanan istanbul_ticaret_odası başkanı murat_yalçıntaş ın da aralarında bulunduğu 15 sanık hakkında soruşturma evresinde elde edilen delillerden bir kısmının hukuka uygun olmaması nedeniyle verdiği beraat kararını değerlendirdi bu bir takdir meselesidir diyen adalı anayasa_mahkemesi üyelerinin görüşlerine saygı duyduğunu söyledi adalı kanun dışı delillerin davanın seyrini değiştirebilecek durumda ise kabul edilebileceğini belirtti rüşvet alınıp verilirken kameralar çalışmamış tam çekemeyince ortada bir şey yok sadece polislerin gördük dediği olaylar var diyen adalı anayasa_mahkemesi üyelerinin çoğunluğunun bunu kabul etmediğini kaydetti adalı bu üyelerin takip etmenin hakim kararıyla olması gerekirken adalet müfettişinin emriyle yapıldığını söylediklerini karara muhalif olan üyelerin ise müfettişlerin resmi makam oluşları ve güvenlik güçlerinin onların emriyle takip etmesini makul karşıladıklarını belirterek bunu delil saydıklarını bildirdi mesut_yılmaz hakkındaki iddia adalı size göre yasa dışı elde edilen deliller kabul edilebilir mi sorusuna mesut_yılmaz ın 2006 da yüce_divan da yargılandığı davayla ilgili görüşünü açıklayarak şu yanıtı verdi anayasa_mahkemesi yılmaz ın yüce_divan da yargılanmasında böyle bir durumu kaale almıştı yasa dışı elde edilen delillerin araştırılmasını kabul etmişti mahkemeye yurt dışından imzası olmayan sahte isimle bir mektup gelmişti mektupta mesut_yılmaz ın isviçre nin şu bankasındaki şu numaralı hesabında 14 milyon doları var deniliyordu mahkeme bunu çok tartıştı imzasız mektup asla kabul edilemez denildi ama ortada 14 milyon dolar gibi yüksek bir rakam vardı ya doğruysa hiç değilse soralım denildi ve isviçre deki bankaya soruldu banka ticari sırdır mudilerimizin hesabının sırrını veremeyiz dedi mahkeme ısrar etti ikinci kez devlet adına istedi gene vermediler mahkeme mesut_yılmaz hakkında devlet eski bakanı güneş taner le birlikte türkbank ihalesine fesat karıştırdıkları iddiasıyla yargılandıkları davada davanın kesin hükme bağlanmasını şartla salıverilme yasası uyarınca erteledi daha farklı karar çıkabilecekti adalı o belge delil olsaydı belki ceza alabilirdi sözlerine evet yanıtını verdi adalı eğer hakikaten isviçre den evet doğru bu kadar para var cevabı gelseydi herhalde mahkeme imzasız ve isimsiz diye onu reddetmeyecek ve kaale alacaktı mesut_yılmaz hakkında daha farklı bir karar çıkabilecekti dedi bu durumda yasa dışı elde edilen delillerin kabul edilebileceğini belirten adalı prensipte kabul edilmemesi lazım ama önemli bir bulguya ulaştıracaksa davanın seyrine tesir edecek bir belge şahitlik gibi bir şey ortaya koyacaksa diğer başka deliller de onu destekliyorsa kabul edilebilir diye konuştu coşkun ergül aa')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp_63PmTlDWC"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "df_Spark = df_Spark.withColumn('text', regexp_replace('text', '_', ' '))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Ix9cxAlTGb",
        "outputId": "493a8c56-f93f-4417-bd0d-6c81b1660069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "df_Spark.show(5, truncate=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+----------------------------------------------------------------------------------------------------+\n",
            "|category|                                                                                                text|\n",
            "+--------+----------------------------------------------------------------------------------------------------+\n",
            "|siyaset | 3 milyon ile ön seçim vaadi mhp nin 10 olağan büyük kurultayı nda konuşan genel başkan adayı kor...|\n",
            "|siyaset | mesut yılmaz yüce divan da ceza alabilirdi prof dr sacit adalı isviçre deki banka eski başbakan ...|\n",
            "|siyaset | disko lar kaldırılıyor başbakan yardımcısı arınç disko diye tabir edilen disiplin koğuşlarının k...|\n",
            "|siyaset | sarıgül anayasa mahkemesi ne gidiyor mustafa sarıgül ilçedeki sınır değişikliğine itiraz için an...|\n",
            "|siyaset | erdoğan idamın bir haklılık sebebi var demek ki yeri geldiği zaman idamın bir haklılık sebebi de...|\n",
            "+--------+----------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4N8pf2xpMw-"
      },
      "source": [
        "## Splitting the dataset into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76hYXAYENSEJ"
      },
      "source": [
        "train_news, test_news = df_Spark.randomSplit([0.8, 0.2], seed = 100)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Ph3t_5NxFv",
        "outputId": "4d1a4200-53d1-4921-b60a-cc18fbdc9a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_news.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3Mm6WK5N1YL",
        "outputId": "7026f910-ebe9-486a-a02f-f660d6834773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_news.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIhDkRjet72G"
      },
      "source": [
        "## Setting the Pipeline for ``LogisticRegression`` and ``NaiveBayes`` models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Mcr0GNNbX8",
        "outputId": "9eaa5a27-2253-43aa-86e1-13edb576dd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "stop_words = StopWordsCleaner.pretrained('stopwords_tr', 'tr')\\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"cleanTokens\") \\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "lemmatizer = LemmatizerModel.pretrained(\"lemma\", \"tr\") \\\n",
        "         .setInputCols([\"cleanTokens\"]) \\\n",
        "         .setOutputCol(\"lemma\")\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"lemma\"]) \\\n",
        "    .setOutputCols([\"token_features\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopwords_tr download started this may take some time.\n",
            "Approximate size to download 2 KB\n",
            "[OK!]\n",
            "lemma download started this may take some time.\n",
            "Approximate size to download 14.8 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5dmfhyUIrYo"
      },
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, IndexToString\n",
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2sg-5HuyNvy"
      },
      "source": [
        "## Text Classification with `LogisticRegression`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJdoLErdNKHv"
      },
      "source": [
        "hashTF = HashingTF(inputCol=\"token_features\", outputCol=\"raw_features\")\n",
        "\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=5)\n",
        "\n",
        "label_strIdx = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
        "\n",
        "logReg = LogisticRegression(maxIter=10)\n",
        "\n",
        "label_Idxstr = IndexToString(inputCol=\"label\", outputCol=\"article_class\")\n",
        "\n",
        "nlp_pipeline_lr = Pipeline(\n",
        "        stages=[document, \n",
        "                sentence,\n",
        "                token,\n",
        "                stop_words, \n",
        "                lemmatizer, \n",
        "                finisher,\n",
        "                hashTF,\n",
        "                idf,\n",
        "                label_strIdx,\n",
        "                logReg,\n",
        "                label_Idxstr])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Ps83oqN4OA"
      },
      "source": [
        "classification_model_lr = nlp_pipeline_lr.fit(train_news)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGd1ohqOOmK3"
      },
      "source": [
        "pred_lr = classification_model_lr.transform(test_news)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbshPu-TPYqF",
        "outputId": "23a15948-be93-473d-dfaa-e80a4cf2e5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "pred_lr.select(\"category\", \"label\", \"prediction\").show(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----+----------+\n",
            "|category|label|prediction|\n",
            "+--------+-----+----------+\n",
            "|  dunya |  3.0|       3.0|\n",
            "|  dunya |  3.0|       3.0|\n",
            "|  dunya |  3.0|       3.0|\n",
            "|  dunya |  3.0|       3.0|\n",
            "|  dunya |  3.0|       3.0|\n",
            "+--------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-hZJv6zthEm"
      },
      "source": [
        "- Evaluation of Classification (`LogisticRegression`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2BZdKjbz88a",
        "outputId": "ad19cf0f-8e9b-49f0-86f7-ed567119fe06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred_lr)\n",
        "print(\"Accuracy = %g\" % (accuracy))\n",
        "print(\"Test Error = %g \" % (1.0 - accuracy))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.900099\n",
            "Test Error = 0.0999011 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yytXDvhhPqn7"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO9LE-qZSR_O"
      },
      "source": [
        "df_lr = classification_model_lr \\\n",
        "   .transform(test_news) \\\n",
        "   .select(\"category\", \"label\", \"prediction\") \\\n",
        "   .toPandas()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhMIx5R8ShrY",
        "outputId": "3a01af10-f5bf-48bc-ea5e-43651757e80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df_lr.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  label  prediction\n",
              "0   dunya     3.0         3.0\n",
              "1   dunya     3.0         3.0\n",
              "2   dunya     3.0         3.0\n",
              "3   dunya     3.0         3.0\n",
              "4   dunya     3.0         3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLiyKBrt0Ih-",
        "outputId": "fbd31700-8675-4380-9df2-8e3907c0d611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "print(classification_report(df_lr.label, df_lr.prediction))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.88      0.91       135\n",
            "         1.0       0.87      0.80      0.83       140\n",
            "         2.0       0.83      0.90      0.86       142\n",
            "         3.0       0.87      0.92      0.89       142\n",
            "         4.0       0.91      0.94      0.93       144\n",
            "         5.0       0.90      0.88      0.89       153\n",
            "         6.0       0.99      0.97      0.98       155\n",
            "\n",
            "    accuracy                           0.90      1011\n",
            "   macro avg       0.90      0.90      0.90      1011\n",
            "weighted avg       0.90      0.90      0.90      1011\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTnnf2Z7pg1s"
      },
      "source": [
        "## Text Classification with `NaiveBayes`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up9XDrSl2Omu"
      },
      "source": [
        "hashTF = HashingTF(inputCol=\"token_features\", outputCol=\"raw_features\", numFeatures=4096)\n",
        "\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=5)\n",
        "\n",
        "label_strIdx = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
        "\n",
        "bayes_class = NaiveBayes(smoothing=111)\n",
        "\n",
        "label_Idxstr = IndexToString(inputCol=\"label\", outputCol=\"article_class\")\n",
        "\n",
        "nlp_pipeline_bayes = Pipeline(\n",
        "    stages=[document, \n",
        "            sentence,\n",
        "            token,\n",
        "            stop_words, \n",
        "            lemmatizer, \n",
        "            finisher,\n",
        "            hashTF,\n",
        "            idf,\n",
        "            label_strIdx,\n",
        "            bayes_class,\n",
        "            label_Idxstr])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9RIPijU00oV"
      },
      "source": [
        "classification_model_bayes = nlp_pipeline_bayes.fit(train_news)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URXk_8Ka2DEG"
      },
      "source": [
        "pred_bayes = classification_model_bayes.transform(test_news)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4C6ggjW_kGa",
        "outputId": "31f6366a-8db5-4f9d-f8fa-844ead8d7c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "pred_bayes.select(\"category\", \"label\", \"prediction\").show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----+----------+\n",
            "|category|label|prediction|\n",
            "+--------+-----+----------+\n",
            "|  dunya |  3.0|       3.0|\n",
            "|  dunya |  3.0|       3.0|\n",
            "|  dunya |  3.0|       1.0|\n",
            "|  dunya |  3.0|       1.0|\n",
            "|  dunya |  3.0|       1.0|\n",
            "+--------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuOXl7gjtu93"
      },
      "source": [
        "- Evaluation of Classification (`NaiveBaye`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD8HmtCs07wm",
        "outputId": "b6196ea3-dac1-4951-ac1e-99169bcd9294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(pred_bayes)\n",
        "print(\"Accuracy = %g\" % (accuracy))\n",
        "print(\"Test Error = %g \" % (1.0 - accuracy))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.872404\n",
            "Test Error = 0.127596 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goeg2zgZ_rcS"
      },
      "source": [
        "df_bayes = classification_model_bayes.transform(test_news).select(\"category\", \"label\", \"prediction\").toPandas()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iBRxwkp29Mx",
        "outputId": "16f7ffbd-0296-480d-d238-e3da7f947df5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df_bayes.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dunya</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category  label  prediction\n",
              "0   dunya     3.0         3.0\n",
              "1   dunya     3.0         3.0\n",
              "2   dunya     3.0         3.0\n",
              "3   dunya     3.0         1.0\n",
              "4   dunya     3.0         1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odYll8jD3A__",
        "outputId": "920eb4f3-bb19-461a-c451-a77d1a9868c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "print(classification_report(df_bayes.label, df_bayes.prediction))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.94      0.93       135\n",
            "         1.0       0.77      0.88      0.82       140\n",
            "         2.0       0.76      0.92      0.83       142\n",
            "         3.0       0.89      0.68      0.77       142\n",
            "         4.0       0.90      0.94      0.92       144\n",
            "         5.0       0.91      0.82      0.86       153\n",
            "         6.0       0.99      0.94      0.96       155\n",
            "\n",
            "    accuracy                           0.87      1011\n",
            "   macro avg       0.88      0.87      0.87      1011\n",
            "weighted avg       0.88      0.87      0.87      1011\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAsudCvrXaOZ"
      },
      "source": [
        "## Classification with `BertSentenceEmbeddings` and `GloVeWordEmbeddings`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm65LOW96vsV"
      },
      "source": [
        "\n",
        "## Setting the Pipeline for `Bert(\"labse\")` & ``ClassifierDLApproach``"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stdL4Z3h6BL0",
        "outputId": "a20b091c-1d48-4cd0-aaf9-7b5ee281373c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "embeddings = BertSentenceEmbeddings\\\n",
        "    .pretrained('labse', 'xx') \\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "   .setInputCols([\"sentence_embeddings\"])\\\n",
        "   .setOutputCol(\"class\")\\\n",
        "   .setLabelColumn(\"category\")\\\n",
        "   .setMaxEpochs(5)\\\n",
        "   .setEnableOutputLogs(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopwords_tr download started this may take some time.\n",
            "Approximate size to download 2 KB\n",
            "[OK!]\n",
            "lemma download started this may take some time.\n",
            "Approximate size to download 14.8 MB\n",
            "[OK!]\n",
            "labse download started this may take some time.\n",
            "Approximate size to download 1.7 GB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnd61QrZ-_pu"
      },
      "source": [
        "nlp_pipeline_bert = Pipeline(\n",
        "    stages=[document, \n",
        "            sentence,\n",
        "            token,\n",
        "            stop_words, \n",
        "            lemmatizer, \n",
        "            embeddings,\n",
        "            classsifierdl])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgeel3i6EY_l"
      },
      "source": [
        "classification_model_bert = nlp_pipeline_bert.fit(train_news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy1c8M8CEkHB"
      },
      "source": [
        "df_bert = classification_model_bert.transform(test_news).select(\"category\", \"text\", \"class.result\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KkvT7liULrN",
        "outputId": "4883ae49-1ae4-4dc5-8a76-ea443b91e3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df_bert.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dunya</td>\n",
              "      <td>140 araç birbirine girdi 2 ölü 80 yaralı abd ...</td>\n",
              "      <td>[dunya ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dunya</td>\n",
              "      <td>150 araç birbirine girdi abd de yoğun sis ned...</td>\n",
              "      <td>[dunya ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dunya</td>\n",
              "      <td>150 araç birbirine girdi teksas ta etkili ola...</td>\n",
              "      <td>[dunya ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dunya</td>\n",
              "      <td>2 nükleer santralin daha açılmasını istiyor j...</td>\n",
              "      <td>[ekonomi ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dunya</td>\n",
              "      <td>46 5 milyon dolarlık insani yardım aldı tacik...</td>\n",
              "      <td>[ekonomi ]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text      result\n",
              "0   dunya    140 araç birbirine girdi 2 ölü 80 yaralı abd ...    [dunya ]\n",
              "1   dunya    150 araç birbirine girdi abd de yoğun sis ned...    [dunya ]\n",
              "2   dunya    150 araç birbirine girdi teksas ta etkili ola...    [dunya ]\n",
              "3   dunya    2 nükleer santralin daha açılmasını istiyor j...  [ekonomi ]\n",
              "4   dunya    46 5 milyon dolarlık insani yardım aldı tacik...  [ekonomi ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRX4Ev6nWaag",
        "outputId": "82ebf535-7505-4610-98ee-9afb20e0bcdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "df_bert[\"result\"].str[0].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      dunya \n",
              "1      dunya \n",
              "2      dunya \n",
              "3    ekonomi \n",
              "4    ekonomi \n",
              "Name: result, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BOrOcp7RNK"
      },
      "source": [
        "- Evaluation of Classification (`DLApproach` & `BertEmbeddings`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUDf1nk_WmdE",
        "outputId": "2897ee73-ad51-40a5-fe1e-b28a5ddfb9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "print(classification_report(df_bert.category, df_bert.result.str[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      dunya        0.86      0.80      0.82       142\n",
            "    ekonomi        0.86      0.79      0.82       140\n",
            "     kultur        0.89      0.94      0.92       144\n",
            "     saglik        0.88      0.95      0.91       135\n",
            "    siyaset        0.85      0.85      0.85       142\n",
            "       spor        0.97      0.95      0.96       155\n",
            "  teknoloji        0.84      0.88      0.86       153\n",
            "\n",
            "    accuracy                           0.88      1011\n",
            "   macro avg       0.88      0.88      0.88      1011\n",
            "weighted avg       0.88      0.88      0.88      1011\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff4eBJ2Mo8Jk"
      },
      "source": [
        "## Setting Pipeline for `Glove840B` & `ClassifierDLApproach`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_CtPsi5j9l",
        "outputId": "7db7b517-fc9d-4667-84e3-99895be50391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "stop_words = StopWordsCleaner.pretrained('stopwords_tr', 'tr')\\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"cleanTokens\") \\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "lemmatizer = LemmatizerModel.pretrained(\"lemma\", \"tr\") \\\n",
        "         .setInputCols([\"cleanTokens\"]) \\\n",
        "         .setOutputCol(\"lemma\")\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel().pretrained('glove_840B_300','xx')\\\n",
        "  .setInputCols([\"sentence\",'lemma'])\\\n",
        "  .setOutputCol(\"embeddings\")\\\n",
        "  .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"sentence\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"class\")\\\n",
        "  .setLabelColumn(\"category\")\\\n",
        "  .setBatchSize(8)\\\n",
        "  .setMaxEpochs(50)\\\n",
        "  .setLr(0.003)\\\n",
        "  .setEnableOutputLogs(True)\n",
        "  #.setOutputLogsPath('logs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopwords_tr download started this may take some time.\n",
            "Approximate size to download 2 KB\n",
            "[OK!]\n",
            "lemma download started this may take some time.\n",
            "Approximate size to download 14.8 MB\n",
            "[OK!]\n",
            "glove_840B_300 download started this may take some time.\n",
            "Approximate size to download 2.3 GB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjS4CvlXpR8V"
      },
      "source": [
        "nlp_pipeline_glove = Pipeline(\n",
        "    stages=[document, \n",
        "            token,\n",
        "            stop_words, \n",
        "            lemmatizer, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            classsifierdl])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEcJ5FXxqRpf"
      },
      "source": [
        "classification_model_glove = nlp_pipeline_glove.fit(train_news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYxQvGTqdty"
      },
      "source": [
        "df_glove = classification_model_glove.transform(test_news).select(\"category\", \"text\", \"class.result\").toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slvkYfhXsMjB",
        "outputId": "b8446022-1661-4aca-f5fa-9120363d7984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df_glove.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dunya</td>\n",
              "      <td>140 araç birbirine girdi 2 ölü 80 yaralı abd ...</td>\n",
              "      <td>[dunya ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dunya</td>\n",
              "      <td>150 araç birbirine girdi abd de yoğun sis ned...</td>\n",
              "      <td>[dunya ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dunya</td>\n",
              "      <td>150 araç birbirine girdi teksas ta etkili ola...</td>\n",
              "      <td>[dunya ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dunya</td>\n",
              "      <td>2 nükleer santralin daha açılmasını istiyor j...</td>\n",
              "      <td>[dunya ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dunya</td>\n",
              "      <td>46 5 milyon dolarlık insani yardım aldı tacik...</td>\n",
              "      <td>[ekonomi ]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category                                               text      result\n",
              "0   dunya    140 araç birbirine girdi 2 ölü 80 yaralı abd ...    [dunya ]\n",
              "1   dunya    150 araç birbirine girdi abd de yoğun sis ned...    [dunya ]\n",
              "2   dunya    150 araç birbirine girdi teksas ta etkili ola...    [dunya ]\n",
              "3   dunya    2 nükleer santralin daha açılmasını istiyor j...    [dunya ]\n",
              "4   dunya    46 5 milyon dolarlık insani yardım aldı tacik...  [ekonomi ]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ302F2lsTEk"
      },
      "source": [
        "- Evaluation of `GloveEmbeddings`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7FFAF5l4nRK",
        "outputId": "c7b6b39e-4ab8-429b-fe9a-e8f7d5792877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "print(classification_report(df_glove.category, df_glove.result.str[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      dunya        0.78      0.63      0.70       142\n",
            "    ekonomi        0.63      0.78      0.69       140\n",
            "     kultur        0.83      0.86      0.84       144\n",
            "     saglik        0.82      0.86      0.84       135\n",
            "    siyaset        0.70      0.66      0.68       142\n",
            "       spor        0.89      0.87      0.88       155\n",
            "  teknoloji        0.82      0.76      0.79       153\n",
            "\n",
            "    accuracy                           0.78      1011\n",
            "   macro avg       0.78      0.77      0.77      1011\n",
            "weighted avg       0.78      0.78      0.78      1011\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-3l_07hJOJ3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
